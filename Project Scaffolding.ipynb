{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import os\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import sqlalchemy as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any constants you might need; some have been added for you, and \n",
    "# some you need to fill in\n",
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"weather_data\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the QUERY_DIRECTORY exists\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones\n",
    "In this section, we loaded the taxi shapefile that corresponds location IDs to geographical latitudes and logitudes. \n",
    "* The `load_taxi_zones` function reads the shapefile and use GeoPandas to read the file\n",
    "* The `lookup_coords_for_taxi_zone_id` function takes location IDs and the loaded shapefile and returns a tuple of latitude and logitude\n",
    "* The `make_loc_id_coords_dict` creates a dictionary of location IDs and coordinates that will be used in data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_taxi_zones(shapefile):\n",
    "    taxi_zones = gpd.read_file(shapefile)\n",
    "    return taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5296e8e3-e831-4d68-b1a2-8af4d49c949d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Projected CRS: EPSG:2263>\n",
       "Name: NAD83 / New York Long Island (ftUS)\n",
       "Axis Info [cartesian]:\n",
       "- X[east]: Easting (US survey foot)\n",
       "- Y[north]: Northing (US survey foot)\n",
       "Area of Use:\n",
       "- name: United States (USA) - New York - counties of Bronx; Kings; Nassau; New York; Queens; Richmond; Suffolk.\n",
       "- bounds: (-74.26, 40.47, -71.8, 41.3)\n",
       "Coordinate Operation:\n",
       "- name: SPCS83 New York Long Island zone (US survey foot)\n",
       "- method: Lambert Conic Conformal (2SP)\n",
       "Datum: North American Datum 1983\n",
       "- Ellipsoid: GRS 1980\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_zones = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "taxi_zones.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a924269c-1348-4110-ba72-326f2f258264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_coords_for_taxi_zone_id(zone_loc_id, loaded_taxi_zones=taxi_zones):\n",
    "    zone = loaded_taxi_zones[loaded_taxi_zones[\"LocationID\"] == zone_loc_id]\n",
    "    centroid = zone.geometry.centroid.iloc[0]\n",
    "    centroid_geo = gpd.GeoSeries([centroid], crs=loaded_taxi_zones.crs).to_crs(epsg=CRS).iloc[0]\n",
    "\n",
    "    latitude = centroid_geo.y\n",
    "    longitude = centroid_geo.x\n",
    "\n",
    "    return (latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dae65882-f709-4348-80a0-6276cd04eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loc_id_coords_dict(loaded_taxi_zones):\n",
    "    id_coords_dict = {}\n",
    "    for loc_id in loaded_taxi_zones[\"LocationID\"]:\n",
    "        id_coords_dict[loc_id] = lookup_coords_for_taxi_zone_id(loc_id, loaded_taxi_zones)\n",
    "\n",
    "    return id_coords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e63ccc-1ff3-46cf-8252-d402e9cf1a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ID_COORDS_DICT = make_loc_id_coords_dict(taxi_zones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate Sample Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sample_size(population):\n",
    "    confidence_level = 0.95\n",
    "    margin_of_error = 0.05\n",
    "    proportion = 0.5\n",
    "    \n",
    "    from scipy.stats import norm\n",
    "\n",
    "    z_score = norm.ppf(1 - (1 - confidence_level) / 2)\n",
    "\n",
    "    # Cochranâ€™s\n",
    "    n = (z_score**2 * proportion * (1 - proportion)) / (margin_of_error**2)\n",
    "    \n",
    "    # Adjust for finite population\n",
    "    n_adj = n / (1 + (n - 1) / population)\n",
    "    \n",
    "    return int(round(n_adj)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc33eed4-b2e9-4ab3-94a8-59f04e464c98",
   "metadata": {},
   "source": [
    "### Common Functions\n",
    "* `get_all_urls_from_taxi_page` fetches information on the taxi page and finds all \"Yellow Taxi Trip Records\" urls and \"High Volume For-Hire Vehicle Trip Records\" urls\n",
    "* `find_parquet_urls` uses regex to filter the urls that ends with \".parquet\" to make sure that the urls are parquet files\n",
    "* `download_parquet` creates a directory and downloads relevant parquets into the directory\n",
    "* `get_and_clean_month` filters the urls that are from January 2020 to August 2024\n",
    "* `sample_monthly` function reads all the parquet files in a directory, finds the file with largest number of rows and computes the sample size using the \"maximum population\". Next it creates samples for all files using the computed sample size and combine them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_urls_from_taxi_page(taxi_page):\n",
    "    response = requests.get(taxi_page)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    yellow_tags = soup.find_all(\"a\", attrs={\"title\": \"Yellow Taxi Trip Records\"})\n",
    "    fhvhv_tags = soup.find_all(\"a\", attrs={\"title\": \"High Volume For-Hire Vehicle Trip Records\"})\n",
    "\n",
    "    yellow_urls = [a[\"href\"].strip() for a in yellow_tags]\n",
    "    fhvhv_urls = [a[\"href\"].strip() for a in fhvhv_tags]\n",
    "    \n",
    "    return yellow_urls, fhvhv_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_parquet_urls(urls):\n",
    "    pattern = re.compile(r\"\\.parquet$\")\n",
    "    parquet_urls = [url for url in urls if pattern.search(url)]    \n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b77c3ef5-812f-45db-bed1-d9f8ef52269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_parquet(urls, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for url in urls:\n",
    "        filename = os.path.basename(url)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "        if os.path.exists(output_path):\n",
    "            continue        \n",
    "        response = requests.get(url, stream=True)\n",
    "        with open(output_path, \"wb\") as f:\n",
    "            for chunk in response.iter_content(chunk_size=1024): \n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(f\"Downloaded {filename} to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month(urls):\n",
    "    pattern = re.compile(r\"(202[0-3]-(0[1-9]|1[0-2])|2024-(0[1-8]))\")\n",
    "    cleaned_urls = [url for url in urls if pattern.search(url)]\n",
    "    return cleaned_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2c60ef2-3ab2-44f2-938e-05cbf8868f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_to_df(directory):\n",
    "    files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith(\".parquet\")]\n",
    "    all_dataframe = []\n",
    "    for file in files:\n",
    "        \n",
    "        df = pd.read_parquet(file)\n",
    "        all_dataframe.append(df)\n",
    "    if all_dataframe:\n",
    "        combined_df = pd.concat(all_dataframe, ignore_index=True)\n",
    "        return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "116a75c2-0bfb-4149-9548-47a35f3f2977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_parquet_column(file_path, columns_to_keep):\n",
    "    df = pd.read_parquet(file_path)\n",
    "    cleaned_df = df[columns_to_keep]\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e11d08-6d62-4acd-bf15-3e1fe5ec5a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow_urls, fhvhv_urls = get_all_urls_from_taxi_page(TLC_URL)\n",
    "taxi_parquet = find_parquet_urls(yellow_urls)\n",
    "uber_parquet = find_parquet_urls(fhvhv_urls)\n",
    "taxi_urls = get_and_clean_month(taxi_parquet)\n",
    "uber_urls = get_and_clean_month(uber_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6396fb8-bea9-4db3-a918-59eeeee34518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_monthly(directory):\n",
    "    files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.parquet')]\n",
    "    \n",
    "    max_rows = 0\n",
    "    for file in files:\n",
    "        df = pd.read_parquet(file)\n",
    "        max_rows = max(max_rows, len(df))\n",
    "\n",
    "    sample_size = calculate_sample_size(max_rows)\n",
    "    print(f\"Sample size for all months: {sample_size}\")\n",
    "\n",
    "    sampled_dataframes = []\n",
    "    for file in files:\n",
    "        df = pd.read_parquet(file)\n",
    "        sampled_df = df.sample(n=sample_size, random_state=30, replace=False)\n",
    "        sampled_dataframes.append(sampled_df)\n",
    "    print(\"Finished sampling\")\n",
    "\n",
    "    if sampled_dataframes:\n",
    "        combined_sampled_df = pd.concat(sampled_dataframes, ignore_index=True)\n",
    "        return combined_sampled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb0a333f-84b4-40c6-86e7-f2d56ecba837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "taxi_data_dir = \"taxi_data\"\n",
    "download_parquet(taxi_urls, taxi_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "882a02c9-5fcc-45ac-bdfc-c3b6fb6f1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for all months: 384\n",
      "Finished sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/llw7py457rl4zlvsw5ymljw80000gn/T/ipykernel_49567/1458695063.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_sampled_df = pd.concat(sampled_dataframes, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "sampled_taxi_df = sample_monthly(taxi_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49122c36-026f-439e-97ff-82ea5515d31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>Airport_fee</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-05 06:50:05</td>\n",
       "      <td>2023-06-05 07:11:09</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-12 11:11:39</td>\n",
       "      <td>2023-06-12 11:20:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-07 18:27:39</td>\n",
       "      <td>2023-06-07 18:46:53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>234</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>19.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.72</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-29 21:50:08</td>\n",
       "      <td>2023-06-29 22:04:14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>186</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.20</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-10 22:25:59</td>\n",
       "      <td>2023-06-10 22:36:26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>246</td>\n",
       "      <td>249</td>\n",
       "      <td>1</td>\n",
       "      <td>10.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-20 08:31:24</td>\n",
       "      <td>2023-06-20 09:22:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.40</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-06-27 08:40:33</td>\n",
       "      <td>2023-06-27 08:47:33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-20 14:08:07</td>\n",
       "      <td>2023-06-20 14:21:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>79</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-22 18:17:30</td>\n",
       "      <td>2023-06-22 18:35:05</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.10</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2023-06-22 14:13:38</td>\n",
       "      <td>2023-06-22 14:27:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>144</td>\n",
       "      <td>88</td>\n",
       "      <td>1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.50</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2023-06-05 06:50:05   2023-06-05 07:11:09              3.0   \n",
       "1         2  2023-06-12 11:11:39   2023-06-12 11:20:59              1.0   \n",
       "2         2  2023-06-07 18:27:39   2023-06-07 18:46:53              1.0   \n",
       "3         1  2023-06-29 21:50:08   2023-06-29 22:04:14              2.0   \n",
       "4         1  2023-06-10 22:25:59   2023-06-10 22:36:26              1.0   \n",
       "5         2  2023-06-20 08:31:24   2023-06-20 09:22:59              1.0   \n",
       "6         1  2023-06-27 08:40:33   2023-06-27 08:47:33              1.0   \n",
       "7         2  2023-06-20 14:08:07   2023-06-20 14:21:00              1.0   \n",
       "8         2  2023-06-22 18:17:30   2023-06-22 18:35:05              5.0   \n",
       "9         2  2023-06-22 14:13:38   2023-06-22 14:27:20              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           5.55         1.0                  N           132           197   \n",
       "1           1.71         1.0                  N           239            48   \n",
       "2           2.67         1.0                  N           234           231   \n",
       "3           1.10         1.0                  N           186           230   \n",
       "4           1.20         1.0                  N           246           249   \n",
       "5          11.09         1.0                  N           138           143   \n",
       "6           1.20         1.0                  N           236           151   \n",
       "7           1.58         1.0                  N            79           233   \n",
       "8           0.86         1.0                  N            48           230   \n",
       "9           3.99         1.0                  N           144            88   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         27.5    0.0      0.5        3.25          0.00   \n",
       "1             2         12.1    0.0      0.5        0.00          0.00   \n",
       "2             1         19.1    2.5      0.5        5.12          0.00   \n",
       "3             1         13.5    3.5      0.5        3.70          0.00   \n",
       "4             1         10.7    3.5      0.5        3.10          0.00   \n",
       "5             1         52.0    5.0      0.5       10.40          6.55   \n",
       "6             1          7.9    2.5      0.5        2.40          0.00   \n",
       "7             1         12.8    0.0      0.5        3.36          0.00   \n",
       "8             2         15.6    2.5      0.5        0.00          0.00   \n",
       "9             1         20.5    0.0      0.5        2.00          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  Airport_fee  \\\n",
       "0                    1.0         34.00                   0.0         1.75   \n",
       "1                    1.0         16.10                   2.5         0.00   \n",
       "2                    1.0         30.72                   2.5         0.00   \n",
       "3                    1.0         22.20                   2.5         0.00   \n",
       "4                    1.0         18.80                   2.5         0.00   \n",
       "5                    1.0         79.70                   2.5         1.75   \n",
       "6                    1.0         14.30                   2.5         0.00   \n",
       "7                    1.0         20.16                   2.5         0.00   \n",
       "8                    1.0         22.10                   2.5         0.00   \n",
       "9                    1.0         26.50                   2.5         0.00   \n",
       "\n",
       "   airport_fee  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "5          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "8          NaN  \n",
       "9          NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_taxi_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88b94ce7-5df3-4756-80e4-3697380780f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxidata(dataframe):\n",
    "    try: \n",
    "        print(f\"Cleaning the sample dataframe...\")\n",
    "\n",
    "        if not isinstance(dataframe, pd.DataFrame):\n",
    "            raise ValueError(\"must Pandas DataFrame\")\n",
    "\n",
    "        # look up the latitude and longitude (get those coordinates)\n",
    "        dataframe[[\"latitude_pickup\", \"longitude_pickup\"]] = dataframe[\"PULocationID\"].map(ID_COORDS_DICT).apply(pd.Series)\n",
    "        dataframe[[\"latitude_dropoff\", \"longitude_dropoff\"]] = dataframe[\"DOLocationID\"].map(ID_COORDS_DICT).apply(pd.Series)\n",
    "\n",
    "        # remove some location IDs not valid and distance is 0\n",
    "        dataframe = dataframe.dropna(subset=['latitude_pickup', 'longitude_pickup', 'latitude_dropoff', 'longitude_dropoff'])\n",
    "        dataframe = dataframe[dataframe[\"trip_distance\"] != 0]\n",
    "\n",
    "        # airport_fee combine with Airport_fee\n",
    "        dataframe[\"airport_fee\"] = dataframe[\"Airport_fee\"].combine_first(dataframe[\"airport_fee\"])\n",
    "        dataframe.drop(columns=[\"Airport_fee\"], inplace=True)\n",
    "        dataframe[\"airport_fee\"] = dataframe[\"airport_fee\"].fillna(0)\n",
    "        \n",
    "        # remove unnecessary columns\n",
    "        columns_to_keep = [\n",
    "            'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
    "            'trip_distance', \n",
    "            'latitude_pickup', 'longitude_pickup', 'latitude_dropoff', 'longitude_dropoff', \n",
    "            'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', \n",
    "            'improvement_surcharge', 'congestion_surcharge', 'airport_fee', \n",
    "            'total_amount'\n",
    "        ]\n",
    "        dataframe = dataframe[columns_to_keep]\n",
    "\n",
    "        # normalize column names\n",
    "        dataframe.columns = [col.lower().replace(' ', '_') for col in dataframe.columns]\n",
    "\n",
    "        # normalizing and using appropriate column types for the respective data;\n",
    "        dataframe['tpep_pickup_datetime'] = pd.to_datetime(dataframe['tpep_pickup_datetime'])\n",
    "        dataframe['tpep_dropoff_datetime'] = pd.to_datetime(dataframe['tpep_dropoff_datetime'])\n",
    "        dataframe['trip_distance'] = dataframe['trip_distance'].astype(float)\n",
    "\n",
    "        # caculate part of total_money \n",
    "        dataframe['congestion_surcharge'] = dataframe['congestion_surcharge'].fillna(0)\n",
    "        dataframe['total_money'] = (dataframe['fare_amount'] + dataframe['extra'] + dataframe['mta_tax'] + \n",
    "                                     dataframe['tip_amount'] + dataframe['tolls_amount'] + \n",
    "                                     dataframe['improvement_surcharge'] + dataframe['congestion_surcharge'])\n",
    "\n",
    "        # Add airport_fee to total_money if within airport coordinates\n",
    "        # dataframe['total_money'] += dataframe.apply(lambda row: row['airport_fee'] if \n",
    "        #     (LGA_BOX_COORDS[0][0] <= row['latitude_pickup'] <= LGA_BOX_COORDS[1][0] and \n",
    "        #      LGA_BOX_COORDS[0][1] <= row['longitude_pickup'] <= LGA_BOX_COORDS[1][1]) or \n",
    "        #     (JFK_BOX_COORDS[0][0] <= row['latitude_pickup'] <= JFK_BOX_COORDS[1][0] and \n",
    "        #      JFK_BOX_COORDS[0][1] <= row['longitude_pickup'] <= JFK_BOX_COORDS[1][1]) \n",
    "        #     else 0, axis=1)\n",
    "\n",
    "        # Compare total_money with total_amount\n",
    "        comparison_result = (dataframe['total_money'] == dataframe['total_amount'])\n",
    "        print(f\"Total money matches total amount: {comparison_result.all()}\")\n",
    "\n",
    "        # for Yellow Taxi data, remove trips that start and/or end outside of (40.560445, -74.242330) and (40.908524, -73.717047) ie NEW_YORK_BOX_COORDS.\n",
    "        lat_min, lon_min = NEW_YORK_BOX_COORDS[0]\n",
    "        lat_max, lon_max = NEW_YORK_BOX_COORDS[1]\n",
    "\n",
    "        dataframe = dataframe[\n",
    "            (dataframe['latitude_pickup'].between(lat_min, lat_max)) &\n",
    "            (dataframe['longitude_pickup'].between(lon_min, lon_max)) &\n",
    "            (dataframe['latitude_dropoff'].between(lat_min, lat_max)) &\n",
    "            (dataframe['longitude_dropoff'].between(lon_min, lon_max))\n",
    "        ]\n",
    "\n",
    "        return dataframe\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing the dataframe: {e}\")\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "508ab469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning the sample dataframe...\n",
      "Total money matches total amount: False\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_and_clean_taxidata(sampled_taxi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10ebd75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>latitude_pickup</th>\n",
       "      <th>longitude_pickup</th>\n",
       "      <th>latitude_dropoff</th>\n",
       "      <th>longitude_dropoff</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>total_money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-05 06:50:05</td>\n",
       "      <td>2023-06-05 07:11:09</td>\n",
       "      <td>5.55</td>\n",
       "      <td>40.646985</td>\n",
       "      <td>-73.786530</td>\n",
       "      <td>40.694542</td>\n",
       "      <td>-73.830924</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>34.00</td>\n",
       "      <td>32.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-06-12 11:11:39</td>\n",
       "      <td>2023-06-12 11:20:59</td>\n",
       "      <td>1.71</td>\n",
       "      <td>40.783961</td>\n",
       "      <td>-73.978632</td>\n",
       "      <td>40.762253</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>12.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.10</td>\n",
       "      <td>16.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-06-07 18:27:39</td>\n",
       "      <td>2023-06-07 18:46:53</td>\n",
       "      <td>2.67</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.717773</td>\n",
       "      <td>-74.007880</td>\n",
       "      <td>19.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.72</td>\n",
       "      <td>30.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-06-29 21:50:08</td>\n",
       "      <td>2023-06-29 22:04:14</td>\n",
       "      <td>1.10</td>\n",
       "      <td>40.748497</td>\n",
       "      <td>-73.992438</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.984197</td>\n",
       "      <td>13.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.20</td>\n",
       "      <td>24.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-06-10 22:25:59</td>\n",
       "      <td>2023-06-10 22:36:26</td>\n",
       "      <td>1.20</td>\n",
       "      <td>40.753309</td>\n",
       "      <td>-74.004016</td>\n",
       "      <td>40.734576</td>\n",
       "      <td>-74.002875</td>\n",
       "      <td>10.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.80</td>\n",
       "      <td>21.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-06-20 08:31:24</td>\n",
       "      <td>2023-06-20 09:22:59</td>\n",
       "      <td>11.09</td>\n",
       "      <td>40.774376</td>\n",
       "      <td>-73.873628</td>\n",
       "      <td>40.775965</td>\n",
       "      <td>-73.987646</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.40</td>\n",
       "      <td>6.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>79.70</td>\n",
       "      <td>77.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-06-27 08:40:33</td>\n",
       "      <td>2023-06-27 08:47:33</td>\n",
       "      <td>1.20</td>\n",
       "      <td>40.780436</td>\n",
       "      <td>-73.957012</td>\n",
       "      <td>40.797962</td>\n",
       "      <td>-73.968168</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.30</td>\n",
       "      <td>16.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-06-20 14:08:07</td>\n",
       "      <td>2023-06-20 14:21:00</td>\n",
       "      <td>1.58</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.749914</td>\n",
       "      <td>-73.970443</td>\n",
       "      <td>12.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.16</td>\n",
       "      <td>20.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-06-22 18:17:30</td>\n",
       "      <td>2023-06-22 18:35:05</td>\n",
       "      <td>0.86</td>\n",
       "      <td>40.762253</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>40.759818</td>\n",
       "      <td>-73.984197</td>\n",
       "      <td>15.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.10</td>\n",
       "      <td>22.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-06-22 14:13:38</td>\n",
       "      <td>2023-06-22 14:27:20</td>\n",
       "      <td>3.99</td>\n",
       "      <td>40.720889</td>\n",
       "      <td>-73.996919</td>\n",
       "      <td>40.703358</td>\n",
       "      <td>-74.011515</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26.50</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tpep_pickup_datetime tpep_dropoff_datetime  trip_distance  latitude_pickup  \\\n",
       "0  2023-06-05 06:50:05   2023-06-05 07:11:09           5.55        40.646985   \n",
       "1  2023-06-12 11:11:39   2023-06-12 11:20:59           1.71        40.783961   \n",
       "2  2023-06-07 18:27:39   2023-06-07 18:46:53           2.67        40.740337   \n",
       "3  2023-06-29 21:50:08   2023-06-29 22:04:14           1.10        40.748497   \n",
       "4  2023-06-10 22:25:59   2023-06-10 22:36:26           1.20        40.753309   \n",
       "5  2023-06-20 08:31:24   2023-06-20 09:22:59          11.09        40.774376   \n",
       "6  2023-06-27 08:40:33   2023-06-27 08:47:33           1.20        40.780436   \n",
       "7  2023-06-20 14:08:07   2023-06-20 14:21:00           1.58        40.727620   \n",
       "8  2023-06-22 18:17:30   2023-06-22 18:35:05           0.86        40.762253   \n",
       "9  2023-06-22 14:13:38   2023-06-22 14:27:20           3.99        40.720889   \n",
       "\n",
       "   longitude_pickup  latitude_dropoff  longitude_dropoff  fare_amount  extra  \\\n",
       "0        -73.786530         40.694542         -73.830924         27.5    0.0   \n",
       "1        -73.978632         40.762253         -73.989845         12.1    0.0   \n",
       "2        -73.990458         40.717773         -74.007880         19.1    2.5   \n",
       "3        -73.992438         40.759818         -73.984197         13.5    3.5   \n",
       "4        -74.004016         40.734576         -74.002875         10.7    3.5   \n",
       "5        -73.873628         40.775965         -73.987646         52.0    5.0   \n",
       "6        -73.957012         40.797962         -73.968168          7.9    2.5   \n",
       "7        -73.985937         40.749914         -73.970443         12.8    0.0   \n",
       "8        -73.989845         40.759818         -73.984197         15.6    2.5   \n",
       "9        -73.996919         40.703358         -74.011515         20.5    0.0   \n",
       "\n",
       "   mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
       "0      0.5        3.25          0.00                    1.0   \n",
       "1      0.5        0.00          0.00                    1.0   \n",
       "2      0.5        5.12          0.00                    1.0   \n",
       "3      0.5        3.70          0.00                    1.0   \n",
       "4      0.5        3.10          0.00                    1.0   \n",
       "5      0.5       10.40          6.55                    1.0   \n",
       "6      0.5        2.40          0.00                    1.0   \n",
       "7      0.5        3.36          0.00                    1.0   \n",
       "8      0.5        0.00          0.00                    1.0   \n",
       "9      0.5        2.00          0.00                    1.0   \n",
       "\n",
       "   congestion_surcharge  airport_fee  total_amount  total_money  \n",
       "0                   0.0         1.75         34.00        32.25  \n",
       "1                   2.5         0.00         16.10        16.10  \n",
       "2                   2.5         0.00         30.72        30.72  \n",
       "3                   2.5         0.00         22.20        24.70  \n",
       "4                   2.5         0.00         18.80        21.30  \n",
       "5                   2.5         1.75         79.70        77.95  \n",
       "6                   2.5         0.00         14.30        16.80  \n",
       "7                   2.5         0.00         20.16        20.16  \n",
       "8                   2.5         0.00         22.10        22.10  \n",
       "9                   2.5         0.00         26.50        26.50  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9da7089-3f6b-4f93-a22e-76bf554daca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20869 entries, 0 to 21503\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   tpep_pickup_datetime   20869 non-null  datetime64[us]\n",
      " 1   tpep_dropoff_datetime  20869 non-null  datetime64[us]\n",
      " 2   trip_distance          20869 non-null  float64       \n",
      " 3   latitude_pickup        20869 non-null  float64       \n",
      " 4   longitude_pickup       20869 non-null  float64       \n",
      " 5   latitude_dropoff       20869 non-null  float64       \n",
      " 6   longitude_dropoff      20869 non-null  float64       \n",
      " 7   fare_amount            20869 non-null  float64       \n",
      " 8   extra                  20869 non-null  float64       \n",
      " 9   mta_tax                20869 non-null  float64       \n",
      " 10  tip_amount             20869 non-null  float64       \n",
      " 11  tolls_amount           20869 non-null  float64       \n",
      " 12  improvement_surcharge  20869 non-null  float64       \n",
      " 13  congestion_surcharge   20869 non-null  float64       \n",
      " 14  airport_fee            20869 non-null  float64       \n",
      " 15  total_amount           20869 non-null  float64       \n",
      " 16  total_money            20869 non-null  float64       \n",
      "dtypes: datetime64[us](2), float64(15)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "taxi_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "50c85e25-6416-4c16-b98c-09596cdc6865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>latitude_pickup</th>\n",
       "      <th>longitude_pickup</th>\n",
       "      <th>latitude_dropoff</th>\n",
       "      <th>longitude_dropoff</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>total_money</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20869</td>\n",
       "      <td>20869</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "      <td>20869.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-01 23:23:35.520628</td>\n",
       "      <td>2022-05-01 23:40:27.647515</td>\n",
       "      <td>3.313074</td>\n",
       "      <td>40.753511</td>\n",
       "      <td>-73.966552</td>\n",
       "      <td>40.755856</td>\n",
       "      <td>-73.970556</td>\n",
       "      <td>15.666208</td>\n",
       "      <td>1.228502</td>\n",
       "      <td>0.490718</td>\n",
       "      <td>2.726723</td>\n",
       "      <td>0.456978</td>\n",
       "      <td>0.544477</td>\n",
       "      <td>2.183502</td>\n",
       "      <td>0.082922</td>\n",
       "      <td>22.794868</td>\n",
       "      <td>23.297109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:20:28</td>\n",
       "      <td>2020-01-01 00:33:35</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.167234</td>\n",
       "      <td>40.576961</td>\n",
       "      <td>-74.174002</td>\n",
       "      <td>-171.700000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.380000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-2.500000</td>\n",
       "      <td>-1.750000</td>\n",
       "      <td>-188.080000</td>\n",
       "      <td>-188.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-28 14:22:00</td>\n",
       "      <td>2021-02-28 14:42:00</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>40.740439</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>13.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-04-30 10:32:36</td>\n",
       "      <td>2022-04-30 10:44:33</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>40.758028</td>\n",
       "      <td>-73.977698</td>\n",
       "      <td>10.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>17.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-07-01 09:11:58</td>\n",
       "      <td>2023-07-01 09:26:38</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>40.773633</td>\n",
       "      <td>-73.961764</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.959635</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.500000</td>\n",
       "      <td>25.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 23:35:57</td>\n",
       "      <td>2024-08-31 23:44:08</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>40.897932</td>\n",
       "      <td>-73.735554</td>\n",
       "      <td>40.899528</td>\n",
       "      <td>-73.726655</td>\n",
       "      <td>7000.500000</td>\n",
       "      <td>11.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>33.440000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>7010.850000</td>\n",
       "      <td>7010.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.135789</td>\n",
       "      <td>0.032516</td>\n",
       "      <td>0.045546</td>\n",
       "      <td>0.033581</td>\n",
       "      <td>0.037030</td>\n",
       "      <td>50.405868</td>\n",
       "      <td>1.513872</td>\n",
       "      <td>0.088052</td>\n",
       "      <td>3.153968</td>\n",
       "      <td>1.878248</td>\n",
       "      <td>0.350941</td>\n",
       "      <td>0.871432</td>\n",
       "      <td>0.349541</td>\n",
       "      <td>51.654328</td>\n",
       "      <td>51.577493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tpep_pickup_datetime       tpep_dropoff_datetime  trip_distance  \\\n",
       "count                       20869                       20869   20869.000000   \n",
       "mean   2022-05-01 23:23:35.520628  2022-05-01 23:40:27.647515       3.313074   \n",
       "min           2020-01-01 00:20:28         2020-01-01 00:33:35       0.010000   \n",
       "25%           2021-02-28 14:22:00         2021-02-28 14:42:00       1.090000   \n",
       "50%           2022-04-30 10:32:36         2022-04-30 10:44:33       1.810000   \n",
       "75%           2023-07-01 09:11:58         2023-07-01 09:26:38       3.400000   \n",
       "max           2024-08-31 23:35:57         2024-08-31 23:44:08      55.600000   \n",
       "std                           NaN                         NaN       4.135789   \n",
       "\n",
       "       latitude_pickup  longitude_pickup  latitude_dropoff  longitude_dropoff  \\\n",
       "count     20869.000000      20869.000000      20869.000000       20869.000000   \n",
       "mean         40.753511        -73.966552         40.755856         -73.970556   \n",
       "min          40.576961        -74.167234         40.576961         -74.174002   \n",
       "25%          40.740439        -73.989845         40.740337         -73.989845   \n",
       "50%          40.758028        -73.977698         40.758028         -73.977698   \n",
       "75%          40.773633        -73.961764         40.775932         -73.959635   \n",
       "max          40.897932        -73.735554         40.899528         -73.726655   \n",
       "std           0.032516          0.045546          0.033581           0.037030   \n",
       "\n",
       "        fare_amount         extra       mta_tax    tip_amount  tolls_amount  \\\n",
       "count  20869.000000  20869.000000  20869.000000  20869.000000  20869.000000   \n",
       "mean      15.666208      1.228502      0.490718      2.726723      0.456978   \n",
       "min     -171.700000     -5.000000     -0.500000      0.000000    -15.380000   \n",
       "25%        7.200000      0.000000      0.500000      0.000000      0.000000   \n",
       "50%       10.700000      0.500000      0.500000      2.160000      0.000000   \n",
       "75%       17.500000      2.500000      0.500000      3.500000      0.000000   \n",
       "max     7000.500000     11.750000      0.800000     33.440000     40.000000   \n",
       "std       50.405868      1.513872      0.088052      3.153968      1.878248   \n",
       "\n",
       "       improvement_surcharge  congestion_surcharge   airport_fee  \\\n",
       "count           20869.000000          20869.000000  20869.000000   \n",
       "mean                0.544477              2.183502      0.082922   \n",
       "min                -1.000000             -2.500000     -1.750000   \n",
       "25%                 0.300000              2.500000      0.000000   \n",
       "50%                 0.300000              2.500000      0.000000   \n",
       "75%                 1.000000              2.500000      0.000000   \n",
       "max                 1.000000              2.500000      1.750000   \n",
       "std                 0.350941              0.871432      0.349541   \n",
       "\n",
       "       total_amount   total_money  \n",
       "count  20869.000000  20869.000000  \n",
       "mean      22.794868     23.297109  \n",
       "min     -188.080000   -188.080000  \n",
       "25%       12.600000     13.300000  \n",
       "50%       16.800000     17.660000  \n",
       "75%       24.500000     25.200000  \n",
       "max     7010.850000   7010.850000  \n",
       "std       51.654328     51.577493  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "This section downloads the relevant parquet files from the taxi website and creates a sample according to the sampling function of the Uber data. The sample dataframe is cleaned using the `get_and_clean_uber_data` function.\n",
    "\n",
    "* The `filter_uber_and_sample_monthly` function uses similar logic as the `sample_monthly` function, but it filters Uber trips before sampling\n",
    "\n",
    "* reads parquet files in the directory and filter Uber data each month, then creates a sample of each month and integrate the sample datasets into one dataset.\n",
    "\n",
    "* The `get_and_clean_uber_data` function takes a dataframe and returns a cleaned dataframe that:\n",
    "    * Filtered Uber rides\n",
    "    * Converted Location IDs to latitude lognitude coordinates\n",
    "    * Computed total fares for each ride\n",
    "    * Filtered rides that start and/or end within the New York bounding box\n",
    "    * Dropped columns that are irrelevant to later parts of the project\n",
    "    * Normalized column names and removed invalid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40e29d34-cecb-4b05-a695-02de44a7cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data_dir = \"uber_data\"\n",
    "download_parquet(uber_urls, uber_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6d8d281-4eed-4f0b-87e0-6189beef9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_uber_and_sample_monthly(directory):\n",
    "    files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.parquet')]\n",
    "    \n",
    "    max_rows = 0\n",
    "    for file in files:\n",
    "        df = pd.read_parquet(file, columns=[\"hvfhs_license_num\"])\n",
    "        filtered_df = df[df[\"hvfhs_license_num\"] == \"HV0003\"]\n",
    "        max_rows = max(max_rows, len(filtered_df))\n",
    "    sample_size = calculate_sample_size(max_rows)\n",
    "    print(f\"Sample size for all months: {sample_size}\")\n",
    "    \n",
    "    sampled_dataframes = []\n",
    "    for file in files:\n",
    "        df = pd.read_parquet(file)\n",
    "        filtered_df = df[df[\"hvfhs_license_num\"] == \"HV0003\"]\n",
    "        sampled_df = filtered_df.sample(n=sample_size, random_state=30, replace=False)\n",
    "        sampled_dataframes.append(sampled_df)\n",
    "\n",
    "    if sampled_dataframes:\n",
    "        combined_sampled_df = pd.concat(sampled_dataframes, ignore_index=True)\n",
    "        return combined_sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "322ce07f-c67c-41a2-8998-2e2421aef2d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample size for all months: 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rm/llw7py457rl4zlvsw5ymljw80000gn/T/ipykernel_49567/1403387323.py:20: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_sampled_df = pd.concat(sampled_dataframes, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "sampled_uber_df = filter_uber_and_sample_monthly(uber_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cbca549f-a7ec-4b73-b534-52abd1702717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hvfhs_license_num</th>\n",
       "      <th>dispatching_base_num</th>\n",
       "      <th>originating_base_num</th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>...</th>\n",
       "      <th>sales_tax</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>tips</th>\n",
       "      <th>driver_pay</th>\n",
       "      <th>shared_request_flag</th>\n",
       "      <th>shared_match_flag</th>\n",
       "      <th>access_a_ride_flag</th>\n",
       "      <th>wav_request_flag</th>\n",
       "      <th>wav_match_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02765</td>\n",
       "      <td>B02765</td>\n",
       "      <td>2021-03-25 09:31:19</td>\n",
       "      <td>2021-03-25 09:32:12</td>\n",
       "      <td>2021-03-25 09:34:06</td>\n",
       "      <td>2021-03-25 09:39:19</td>\n",
       "      <td>165</td>\n",
       "      <td>165</td>\n",
       "      <td>1.05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.21</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02888</td>\n",
       "      <td>B02888</td>\n",
       "      <td>2021-03-24 12:18:27</td>\n",
       "      <td>2021-03-24 12:23:05</td>\n",
       "      <td>2021-03-24 12:24:54</td>\n",
       "      <td>2021-03-24 12:53:16</td>\n",
       "      <td>70</td>\n",
       "      <td>35</td>\n",
       "      <td>11.59</td>\n",
       "      <td>...</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.45</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02865</td>\n",
       "      <td>B02865</td>\n",
       "      <td>2021-03-08 12:23:10</td>\n",
       "      <td>2021-03-08 12:25:52</td>\n",
       "      <td>2021-03-08 12:25:52</td>\n",
       "      <td>2021-03-08 12:32:20</td>\n",
       "      <td>262</td>\n",
       "      <td>229</td>\n",
       "      <td>2.19</td>\n",
       "      <td>...</td>\n",
       "      <td>1.24</td>\n",
       "      <td>2.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.16</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02875</td>\n",
       "      <td>B02875</td>\n",
       "      <td>2021-03-04 22:14:05</td>\n",
       "      <td>2021-03-04 22:19:17</td>\n",
       "      <td>2021-03-04 22:19:38</td>\n",
       "      <td>2021-03-04 22:25:14</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.10</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>B02395</td>\n",
       "      <td>B02395</td>\n",
       "      <td>2021-03-16 05:03:32</td>\n",
       "      <td>2021-03-16 05:10:15</td>\n",
       "      <td>2021-03-16 05:12:15</td>\n",
       "      <td>2021-03-16 05:26:09</td>\n",
       "      <td>60</td>\n",
       "      <td>168</td>\n",
       "      <td>2.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.94</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td></td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
       "0            HV0003               B02765               B02765   \n",
       "1            HV0003               B02888               B02888   \n",
       "2            HV0003               B02865               B02865   \n",
       "3            HV0003               B02875               B02875   \n",
       "4            HV0003               B02395               B02395   \n",
       "\n",
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2021-03-25 09:31:19 2021-03-25 09:32:12 2021-03-25 09:34:06   \n",
       "1 2021-03-24 12:18:27 2021-03-24 12:23:05 2021-03-24 12:24:54   \n",
       "2 2021-03-08 12:23:10 2021-03-08 12:25:52 2021-03-08 12:25:52   \n",
       "3 2021-03-04 22:14:05 2021-03-04 22:19:17 2021-03-04 22:19:38   \n",
       "4 2021-03-16 05:03:32 2021-03-16 05:10:15 2021-03-16 05:12:15   \n",
       "\n",
       "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n",
       "0 2021-03-25 09:39:19           165           165        1.05  ...       0.70   \n",
       "1 2021-03-24 12:53:16            70            35       11.59  ...       2.74   \n",
       "2 2021-03-08 12:32:20           262           229        2.19  ...       1.24   \n",
       "3 2021-03-04 22:25:14            25            25        0.83  ...       0.67   \n",
       "4 2021-03-16 05:26:09            60           168        2.71  ...       0.00   \n",
       "\n",
       "   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n",
       "0                  0.00          NaN   0.0        6.21                    N   \n",
       "1                  0.00          NaN   0.0       29.45                    N   \n",
       "2                  2.75          NaN   0.0        7.16                    N   \n",
       "3                  0.00          NaN   3.0        9.10                    N   \n",
       "4                  0.00          NaN   0.0       12.94                    N   \n",
       "\n",
       "   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n",
       "0                  N                                     N              N  \n",
       "1                  N                                     N              N  \n",
       "2                  N                                     N              N  \n",
       "3                  N                                     N              N  \n",
       "4                  N                                     N              N  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_uber_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dca0d9f7-3607-4feb-ac93-810c7b3770ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21504 entries, 0 to 21503\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   hvfhs_license_num     21504 non-null  object        \n",
      " 1   dispatching_base_num  21504 non-null  object        \n",
      " 2   originating_base_num  21500 non-null  object        \n",
      " 3   request_datetime      21504 non-null  datetime64[us]\n",
      " 4   on_scene_datetime     21504 non-null  datetime64[us]\n",
      " 5   pickup_datetime       21504 non-null  datetime64[us]\n",
      " 6   dropoff_datetime      21504 non-null  datetime64[us]\n",
      " 7   PULocationID          21504 non-null  int64         \n",
      " 8   DOLocationID          21504 non-null  int64         \n",
      " 9   trip_miles            21504 non-null  float64       \n",
      " 10  trip_time             21504 non-null  int64         \n",
      " 11  base_passenger_fare   21504 non-null  float64       \n",
      " 12  tolls                 21504 non-null  float64       \n",
      " 13  bcf                   21504 non-null  float64       \n",
      " 14  sales_tax             21504 non-null  float64       \n",
      " 15  congestion_surcharge  21504 non-null  float64       \n",
      " 16  airport_fee           15768 non-null  float64       \n",
      " 17  tips                  21504 non-null  float64       \n",
      " 18  driver_pay            21504 non-null  float64       \n",
      " 19  shared_request_flag   21504 non-null  object        \n",
      " 20  shared_match_flag     21504 non-null  object        \n",
      " 21  access_a_ride_flag    21504 non-null  object        \n",
      " 22  wav_request_flag      21504 non-null  object        \n",
      " 23  wav_match_flag        21504 non-null  object        \n",
      "dtypes: datetime64[us](4), float64(9), int64(3), object(8)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "sampled_uber_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ffb9898b-c1d5-420e-954f-bdf0a9e6fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_uber_data(df):\n",
    "    fare_columns = [\"base_passenger_fare\", \"tolls\", \"bcf\", \"sales_tax\", \"congestion_surcharge\", \"airport_fee\"]\n",
    "    columns_to_keep = [\"request_datetime\", \"on_scene_datetime\", \"pickup_datetime\", \"dropoff_datetime\",\n",
    "                       \"pickup_lat\", \"pickup_lon\", \"dropoff_lat\", \"dropoff_lon\", \"trip_miles\",\n",
    "                       \"total_fare\", \"tips\"]\n",
    "    # filter uber data\n",
    "    df = df[df[\"hvfhs_license_num\"] == \"HV0003\"]\n",
    "\n",
    "    # convert LocationID to coordinates\n",
    "    df[[\"pickup_lat\", \"pickup_lon\"]] = df[\"PULocationID\"].map(ID_COORDS_DICT).apply(pd.Series)\n",
    "    df[[\"dropoff_lat\", \"dropoff_lon\"]] = df[\"DOLocationID\"].map(ID_COORDS_DICT).apply(pd.Series)\n",
    "    \n",
    "    # remove invalid locations & 0 mile trips\n",
    "    df = df.dropna(subset=[\"pickup_lat\", \"pickup_lon\", \"dropoff_lat\", \"dropoff_lon\"])\n",
    "    df = df[df[\"trip_miles\"] != 0]\n",
    "    \n",
    "    # filter trips within the bounding box\n",
    "    ((min_lat, min_lon), (max_lat, max_lon)) = NEW_YORK_BOX_COORDS\n",
    "    pickup_in_box = (\n",
    "        (df[\"pickup_lat\"] >= min_lat) & (df[\"pickup_lat\"] <= max_lat) &\n",
    "        (df[\"pickup_lon\"] >= min_lon) & (df[\"pickup_lon\"] <= max_lon)\n",
    "    )\n",
    "    dropoff_in_box = (\n",
    "        (df[\"dropoff_lat\"] >= min_lat) & (df[\"dropoff_lat\"] <= max_lat) &\n",
    "        (df[\"dropoff_lon\"] >= min_lon) & (df[\"dropoff_lon\"] <= max_lon)\n",
    "    )\n",
    "    df = df[pickup_in_box & dropoff_in_box]\n",
    "        \n",
    "    # compute total fare\n",
    "    df[fare_columns] = df[fare_columns].fillna(0)\n",
    "    df[\"total_fare\"] = df[fare_columns].sum(axis=1)\n",
    "\n",
    "    df = df[columns_to_keep]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8bf7dbd-49a1-49c1-b6d4-1b6767855f6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uber_data = get_and_clean_uber_data(sampled_uber_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7902ce9d-313f-4c3e-9cb6-0e87cb1f4256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>total_fare</th>\n",
       "      <th>tips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-25 09:31:19</td>\n",
       "      <td>2021-03-25 09:32:12</td>\n",
       "      <td>2021-03-25 09:34:06</td>\n",
       "      <td>2021-03-25 09:39:19</td>\n",
       "      <td>40.620924</td>\n",
       "      <td>-73.956824</td>\n",
       "      <td>40.620924</td>\n",
       "      <td>-73.956824</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-24 12:18:27</td>\n",
       "      <td>2021-03-24 12:23:05</td>\n",
       "      <td>2021-03-24 12:24:54</td>\n",
       "      <td>2021-03-24 12:53:16</td>\n",
       "      <td>40.763352</td>\n",
       "      <td>-73.868395</td>\n",
       "      <td>40.664003</td>\n",
       "      <td>-73.910258</td>\n",
       "      <td>11.59</td>\n",
       "      <td>34.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-08 12:23:10</td>\n",
       "      <td>2021-03-08 12:25:52</td>\n",
       "      <td>2021-03-08 12:25:52</td>\n",
       "      <td>2021-03-08 12:32:20</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>2.19</td>\n",
       "      <td>18.40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-04 22:14:05</td>\n",
       "      <td>2021-03-04 22:19:17</td>\n",
       "      <td>2021-03-04 22:19:38</td>\n",
       "      <td>2021-03-04 22:25:14</td>\n",
       "      <td>40.685634</td>\n",
       "      <td>-73.986114</td>\n",
       "      <td>40.685634</td>\n",
       "      <td>-73.986114</td>\n",
       "      <td>0.83</td>\n",
       "      <td>8.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-16 05:03:32</td>\n",
       "      <td>2021-03-16 05:10:15</td>\n",
       "      <td>2021-03-16 05:12:15</td>\n",
       "      <td>2021-03-16 05:26:09</td>\n",
       "      <td>40.833990</td>\n",
       "      <td>-73.885900</td>\n",
       "      <td>40.807347</td>\n",
       "      <td>-73.916822</td>\n",
       "      <td>2.71</td>\n",
       "      <td>16.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-04 16:27:53</td>\n",
       "      <td>2021-03-04 16:30:52</td>\n",
       "      <td>2021-03-04 16:32:20</td>\n",
       "      <td>2021-03-04 16:43:20</td>\n",
       "      <td>40.841708</td>\n",
       "      <td>-73.941399</td>\n",
       "      <td>40.837827</td>\n",
       "      <td>-73.926158</td>\n",
       "      <td>2.28</td>\n",
       "      <td>10.83</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-03-18 20:56:27</td>\n",
       "      <td>2021-03-18 21:00:19</td>\n",
       "      <td>2021-03-18 21:01:06</td>\n",
       "      <td>2021-03-18 21:13:02</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>2.54</td>\n",
       "      <td>18.02</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-03-13 00:35:54</td>\n",
       "      <td>2021-03-13 00:38:16</td>\n",
       "      <td>2021-03-13 00:40:16</td>\n",
       "      <td>2021-03-13 00:49:16</td>\n",
       "      <td>40.640590</td>\n",
       "      <td>-73.976199</td>\n",
       "      <td>40.641886</td>\n",
       "      <td>-74.004653</td>\n",
       "      <td>1.39</td>\n",
       "      <td>6.29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-03-17 15:38:12</td>\n",
       "      <td>2021-03-17 15:41:44</td>\n",
       "      <td>2021-03-17 15:43:26</td>\n",
       "      <td>2021-03-17 16:24:06</td>\n",
       "      <td>40.620924</td>\n",
       "      <td>-73.956824</td>\n",
       "      <td>40.766238</td>\n",
       "      <td>-73.995135</td>\n",
       "      <td>12.48</td>\n",
       "      <td>61.31</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-03-13 12:23:41</td>\n",
       "      <td>2021-03-13 12:26:47</td>\n",
       "      <td>2021-03-13 12:27:54</td>\n",
       "      <td>2021-03-13 12:45:38</td>\n",
       "      <td>40.612218</td>\n",
       "      <td>-73.995259</td>\n",
       "      <td>40.580922</td>\n",
       "      <td>-73.961217</td>\n",
       "      <td>4.08</td>\n",
       "      <td>20.27</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2021-03-25 09:31:19 2021-03-25 09:32:12 2021-03-25 09:34:06   \n",
       "1 2021-03-24 12:18:27 2021-03-24 12:23:05 2021-03-24 12:24:54   \n",
       "2 2021-03-08 12:23:10 2021-03-08 12:25:52 2021-03-08 12:25:52   \n",
       "3 2021-03-04 22:14:05 2021-03-04 22:19:17 2021-03-04 22:19:38   \n",
       "4 2021-03-16 05:03:32 2021-03-16 05:10:15 2021-03-16 05:12:15   \n",
       "5 2021-03-04 16:27:53 2021-03-04 16:30:52 2021-03-04 16:32:20   \n",
       "6 2021-03-18 20:56:27 2021-03-18 21:00:19 2021-03-18 21:01:06   \n",
       "7 2021-03-13 00:35:54 2021-03-13 00:38:16 2021-03-13 00:40:16   \n",
       "8 2021-03-17 15:38:12 2021-03-17 15:41:44 2021-03-17 15:43:26   \n",
       "9 2021-03-13 12:23:41 2021-03-13 12:26:47 2021-03-13 12:27:54   \n",
       "\n",
       "     dropoff_datetime  pickup_lat  pickup_lon  dropoff_lat  dropoff_lon  \\\n",
       "0 2021-03-25 09:39:19   40.620924  -73.956824    40.620924   -73.956824   \n",
       "1 2021-03-24 12:53:16   40.763352  -73.868395    40.664003   -73.910258   \n",
       "2 2021-03-08 12:32:20   40.775932  -73.946510    40.756729   -73.965146   \n",
       "3 2021-03-04 22:25:14   40.685634  -73.986114    40.685634   -73.986114   \n",
       "4 2021-03-16 05:26:09   40.833990  -73.885900    40.807347   -73.916822   \n",
       "5 2021-03-04 16:43:20   40.841708  -73.941399    40.837827   -73.926158   \n",
       "6 2021-03-18 21:13:02   40.740337  -73.990458    40.756729   -73.965146   \n",
       "7 2021-03-13 00:49:16   40.640590  -73.976199    40.641886   -74.004653   \n",
       "8 2021-03-17 16:24:06   40.620924  -73.956824    40.766238   -73.995135   \n",
       "9 2021-03-13 12:45:38   40.612218  -73.995259    40.580922   -73.961217   \n",
       "\n",
       "   trip_miles  total_fare  tips  \n",
       "0        1.05        8.85   0.0  \n",
       "1       11.59       34.59   0.0  \n",
       "2        2.19       18.40   0.0  \n",
       "3        0.83        8.45   3.0  \n",
       "4        2.71       16.80   0.0  \n",
       "5        2.28       10.83   0.0  \n",
       "6        2.54       18.02   0.0  \n",
       "7        1.39        6.29   1.0  \n",
       "8       12.48       61.31   0.0  \n",
       "9        4.08       20.27   3.0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ac89430-73c0-42cf-b690-d9c821e2184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20650 entries, 0 to 21503\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   request_datetime   20650 non-null  datetime64[us]\n",
      " 1   on_scene_datetime  20650 non-null  datetime64[us]\n",
      " 2   pickup_datetime    20650 non-null  datetime64[us]\n",
      " 3   dropoff_datetime   20650 non-null  datetime64[us]\n",
      " 4   pickup_lat         20650 non-null  float64       \n",
      " 5   pickup_lon         20650 non-null  float64       \n",
      " 6   dropoff_lat        20650 non-null  float64       \n",
      " 7   dropoff_lon        20650 non-null  float64       \n",
      " 8   trip_miles         20650 non-null  float64       \n",
      " 9   total_fare         20650 non-null  float64       \n",
      " 10  tips               20650 non-null  float64       \n",
      "dtypes: datetime64[us](4), float64(7)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>total_fare</th>\n",
       "      <th>tips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-25 09:31:19</td>\n",
       "      <td>2021-03-25 09:32:12</td>\n",
       "      <td>2021-03-25 09:34:06</td>\n",
       "      <td>2021-03-25 09:39:19</td>\n",
       "      <td>40.620924</td>\n",
       "      <td>-73.956824</td>\n",
       "      <td>40.620924</td>\n",
       "      <td>-73.956824</td>\n",
       "      <td>1.05</td>\n",
       "      <td>8.85</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-24 12:18:27</td>\n",
       "      <td>2021-03-24 12:23:05</td>\n",
       "      <td>2021-03-24 12:24:54</td>\n",
       "      <td>2021-03-24 12:53:16</td>\n",
       "      <td>40.763352</td>\n",
       "      <td>-73.868395</td>\n",
       "      <td>40.664003</td>\n",
       "      <td>-73.910258</td>\n",
       "      <td>11.59</td>\n",
       "      <td>34.59</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-08 12:23:10</td>\n",
       "      <td>2021-03-08 12:25:52</td>\n",
       "      <td>2021-03-08 12:25:52</td>\n",
       "      <td>2021-03-08 12:32:20</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.946510</td>\n",
       "      <td>40.756729</td>\n",
       "      <td>-73.965146</td>\n",
       "      <td>2.19</td>\n",
       "      <td>18.40</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-03-04 22:14:05</td>\n",
       "      <td>2021-03-04 22:19:17</td>\n",
       "      <td>2021-03-04 22:19:38</td>\n",
       "      <td>2021-03-04 22:25:14</td>\n",
       "      <td>40.685634</td>\n",
       "      <td>-73.986114</td>\n",
       "      <td>40.685634</td>\n",
       "      <td>-73.986114</td>\n",
       "      <td>0.83</td>\n",
       "      <td>8.45</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-03-16 05:03:32</td>\n",
       "      <td>2021-03-16 05:10:15</td>\n",
       "      <td>2021-03-16 05:12:15</td>\n",
       "      <td>2021-03-16 05:26:09</td>\n",
       "      <td>40.833990</td>\n",
       "      <td>-73.885900</td>\n",
       "      <td>40.807347</td>\n",
       "      <td>-73.916822</td>\n",
       "      <td>2.71</td>\n",
       "      <td>16.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
       "0 2021-03-25 09:31:19 2021-03-25 09:32:12 2021-03-25 09:34:06   \n",
       "1 2021-03-24 12:18:27 2021-03-24 12:23:05 2021-03-24 12:24:54   \n",
       "2 2021-03-08 12:23:10 2021-03-08 12:25:52 2021-03-08 12:25:52   \n",
       "3 2021-03-04 22:14:05 2021-03-04 22:19:17 2021-03-04 22:19:38   \n",
       "4 2021-03-16 05:03:32 2021-03-16 05:10:15 2021-03-16 05:12:15   \n",
       "\n",
       "     dropoff_datetime  pickup_lat  pickup_lon  dropoff_lat  dropoff_lon  \\\n",
       "0 2021-03-25 09:39:19   40.620924  -73.956824    40.620924   -73.956824   \n",
       "1 2021-03-24 12:53:16   40.763352  -73.868395    40.664003   -73.910258   \n",
       "2 2021-03-08 12:32:20   40.775932  -73.946510    40.756729   -73.965146   \n",
       "3 2021-03-04 22:25:14   40.685634  -73.986114    40.685634   -73.986114   \n",
       "4 2021-03-16 05:26:09   40.833990  -73.885900    40.807347   -73.916822   \n",
       "\n",
       "   trip_miles  total_fare  tips  \n",
       "0        1.05        8.85   0.0  \n",
       "1       11.59       34.59   0.0  \n",
       "2        2.19       18.40   0.0  \n",
       "3        0.83        8.45   3.0  \n",
       "4        2.71       16.80   0.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74d783db-e527-4847-bf70-2d7428ea3897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 20650 entries, 0 to 21503\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   request_datetime   20650 non-null  datetime64[us]\n",
      " 1   on_scene_datetime  20650 non-null  datetime64[us]\n",
      " 2   pickup_datetime    20650 non-null  datetime64[us]\n",
      " 3   dropoff_datetime   20650 non-null  datetime64[us]\n",
      " 4   pickup_lat         20650 non-null  float64       \n",
      " 5   pickup_lon         20650 non-null  float64       \n",
      " 6   dropoff_lat        20650 non-null  float64       \n",
      " 7   dropoff_lon        20650 non-null  float64       \n",
      " 8   trip_miles         20650 non-null  float64       \n",
      " 9   total_fare         20650 non-null  float64       \n",
      " 10  tips               20650 non-null  float64       \n",
      "dtypes: datetime64[us](4), float64(7)\n",
      "memory usage: 1.9 MB\n"
     ]
    }
   ],
   "source": [
    "uber_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6fddeb14-cd70-4e83-8f93-974642c3bea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>request_datetime</th>\n",
       "      <th>on_scene_datetime</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>pickup_lat</th>\n",
       "      <th>pickup_lon</th>\n",
       "      <th>dropoff_lat</th>\n",
       "      <th>dropoff_lon</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>total_fare</th>\n",
       "      <th>tips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20650</td>\n",
       "      <td>20650</td>\n",
       "      <td>20650</td>\n",
       "      <td>20650</td>\n",
       "      <td>20650.000000</td>\n",
       "      <td>20650.000000</td>\n",
       "      <td>20650.000000</td>\n",
       "      <td>20650.000000</td>\n",
       "      <td>20650.000000</td>\n",
       "      <td>2.065000e+04</td>\n",
       "      <td>20650.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-04-29 17:28:44.550799</td>\n",
       "      <td>2022-04-29 17:32:18.193753</td>\n",
       "      <td>2022-04-29 17:33:26.248184</td>\n",
       "      <td>2022-04-29 17:51:28.953462</td>\n",
       "      <td>40.738333</td>\n",
       "      <td>-73.934669</td>\n",
       "      <td>40.737495</td>\n",
       "      <td>-73.934471</td>\n",
       "      <td>4.437571</td>\n",
       "      <td>2.569772e+01</td>\n",
       "      <td>0.815646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:26:03</td>\n",
       "      <td>2020-01-01 00:35:28</td>\n",
       "      <td>2020-01-01 00:36:58</td>\n",
       "      <td>2020-01-01 00:41:39</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.170885</td>\n",
       "      <td>40.561994</td>\n",
       "      <td>-74.186421</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-02-25 21:54:38.500000</td>\n",
       "      <td>2021-02-25 21:56:17.250000</td>\n",
       "      <td>2021-02-25 21:57:11.250000</td>\n",
       "      <td>2021-02-25 22:09:12.750000</td>\n",
       "      <td>40.691507</td>\n",
       "      <td>-73.984197</td>\n",
       "      <td>40.690787</td>\n",
       "      <td>-73.984052</td>\n",
       "      <td>1.540000</td>\n",
       "      <td>1.248000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-04-27 20:18:27.500000</td>\n",
       "      <td>2022-04-27 20:23:05</td>\n",
       "      <td>2022-04-27 20:23:24</td>\n",
       "      <td>2022-04-27 20:51:21</td>\n",
       "      <td>40.737698</td>\n",
       "      <td>-73.948522</td>\n",
       "      <td>40.737698</td>\n",
       "      <td>-73.947442</td>\n",
       "      <td>2.795000</td>\n",
       "      <td>1.966000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-06-29 17:47:55</td>\n",
       "      <td>2023-06-29 17:51:19</td>\n",
       "      <td>2023-06-29 17:52:39</td>\n",
       "      <td>2023-06-29 18:02:40.750000</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.899735</td>\n",
       "      <td>40.775932</td>\n",
       "      <td>-73.898957</td>\n",
       "      <td>5.680000</td>\n",
       "      <td>3.202000e+01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-08-31 23:33:56</td>\n",
       "      <td>2024-08-31 23:39:56</td>\n",
       "      <td>2024-08-31 23:41:13</td>\n",
       "      <td>2024-09-01 00:23:56</td>\n",
       "      <td>40.899528</td>\n",
       "      <td>-73.726655</td>\n",
       "      <td>40.899528</td>\n",
       "      <td>-73.726655</td>\n",
       "      <td>50.530000</td>\n",
       "      <td>3.114300e+02</td>\n",
       "      <td>41.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.063956</td>\n",
       "      <td>0.068735</td>\n",
       "      <td>0.068116</td>\n",
       "      <td>4.374298</td>\n",
       "      <td>1.976913e+01</td>\n",
       "      <td>2.463201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 request_datetime           on_scene_datetime  \\\n",
       "count                       20650                       20650   \n",
       "mean   2022-04-29 17:28:44.550799  2022-04-29 17:32:18.193753   \n",
       "min           2020-01-01 00:26:03         2020-01-01 00:35:28   \n",
       "25%    2021-02-25 21:54:38.500000  2021-02-25 21:56:17.250000   \n",
       "50%    2022-04-27 20:18:27.500000         2022-04-27 20:23:05   \n",
       "75%           2023-06-29 17:47:55         2023-06-29 17:51:19   \n",
       "max           2024-08-31 23:33:56         2024-08-31 23:39:56   \n",
       "std                           NaN                         NaN   \n",
       "\n",
       "                  pickup_datetime            dropoff_datetime    pickup_lat  \\\n",
       "count                       20650                       20650  20650.000000   \n",
       "mean   2022-04-29 17:33:26.248184  2022-04-29 17:51:28.953462     40.738333   \n",
       "min           2020-01-01 00:36:58         2020-01-01 00:41:39     40.561994   \n",
       "25%    2021-02-25 21:57:11.250000  2021-02-25 22:09:12.750000     40.691507   \n",
       "50%           2022-04-27 20:23:24         2022-04-27 20:51:21     40.737698   \n",
       "75%           2023-06-29 17:52:39  2023-06-29 18:02:40.750000     40.775932   \n",
       "max           2024-08-31 23:41:13         2024-09-01 00:23:56     40.899528   \n",
       "std                           NaN                         NaN      0.068433   \n",
       "\n",
       "         pickup_lon   dropoff_lat   dropoff_lon    trip_miles    total_fare  \\\n",
       "count  20650.000000  20650.000000  20650.000000  20650.000000  2.065000e+04   \n",
       "mean     -73.934669     40.737495    -73.934471      4.437571  2.569772e+01   \n",
       "min      -74.170885     40.561994    -74.186421      0.020000 -1.110223e-16   \n",
       "25%      -73.984197     40.690787    -73.984052      1.540000  1.248000e+01   \n",
       "50%      -73.948522     40.737698    -73.947442      2.795000  1.966000e+01   \n",
       "75%      -73.899735     40.775932    -73.898957      5.680000  3.202000e+01   \n",
       "max      -73.726655     40.899528    -73.726655     50.530000  3.114300e+02   \n",
       "std        0.063956      0.068735      0.068116      4.374298  1.976913e+01   \n",
       "\n",
       "               tips  \n",
       "count  20650.000000  \n",
       "mean       0.815646  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max       41.360000  \n",
       "std        2.463201  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uber_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "In this section, we processed the weather data and creates dataframes with hourly and daily granularity information retaining relevant information only.\n",
    "*  `get_all_weather_csvs` returns the weather csv files in the directory\n",
    "*  `clean_month_weather_data_hourly` takes csv files and returns a dataframe that contains hourly precipation and wind speed information\n",
    "*  `clean_month_weather_data_daily` takes csv files and returns a dataframe that contains daily precipation, wind speed, and snowfall information. The function fills in values according to the data description for better data processing later\n",
    "*  `load_and_clean_weather_data` concatnates all daily dataframes and all hourly dataframes into two large dataframes that contains all daily weather data and all hourly data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_weather_csvs(directory):\n",
    "    weather_csvs = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "    return weather_csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76e864ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    \n",
    "    df[\"date\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df[\"HourlyPrecipitation\"] = (df[\"HourlyPrecipitation\"]\n",
    "        .replace(\"T\", \"0.005\")  # Replace 'T' (trace) with a small float\n",
    "        .str.extract(r\"([\\d\\.]+)\")  # Extract numeric part, ignore non-numeric\n",
    "        .astype(float)  # Convert to float\n",
    "    )\n",
    "\n",
    "    columns = [\"date\", \"HourlyPrecipitation\", \"HourlyWindSpeed\"]\n",
    "    df = df[columns]\n",
    "    \n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "    df.fillna(0, inplace=True)\n",
    "    df.columns = df.columns.str.lower()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    df = pd.read_csv(csv_file, low_memory=False)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"DATE\"])\n",
    "\n",
    "    df[\"DailyPrecipitation\"] = (df[\"DailyPrecipitation\"]\n",
    "            .replace(\"T\", \"0.005\")  \n",
    "            .str.extract(r\"([\\d\\.]+)\")  \n",
    "            .astype(float)  \n",
    "    )\n",
    "    df[\"DailySnowfall\"] = (df[\"DailySnowfall\"]\n",
    "            .replace(\"T\", \"0.005\")  \n",
    "            .str.extract(r\"([\\d\\.]+)\")  \n",
    "            .astype(float) \n",
    "    )\n",
    "    df[\"DailySnowDepth\"] = (df[\"DailySnowDepth\"].replace(\"T\", \"0.005\").astype(float))\n",
    "    \n",
    "    columns = [\"date\", \"DailyPrecipitation\", \"DailyAverageWindSpeed\", \"DailyPeakWindSpeed\",\n",
    "               \"DailySnowfall\", \"DailySnowDepth\"]\n",
    "    df = df[columns]\n",
    "\n",
    "    df = df.dropna(subset=[\"date\", \"DailyPrecipitation\", \"DailyAverageWindSpeed\", \"DailyPeakWindSpeed\",\n",
    "               \"DailySnowfall\", \"DailySnowDepth\"])\n",
    "    rename_map = {\n",
    "        \"date\": \"observation_date\",\n",
    "        \"DailyPrecipitation\": \"daily_precipitation\",\n",
    "        \"DailyAverageWindSpeed\": \"daily_average_wind_speed\",\n",
    "        \"DailyPeakWindSpeed\": \"daily_peak_wind_speed\",\n",
    "        \"DailySnowfall\": \"daily_snowfall\",\n",
    "        \"DailySnowDepth\": \"daily_snow_depth\",\n",
    "    }\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    weather_csv_files = get_all_weather_csvs(WEATHER_CSV_DIR)\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f7cd53a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c8230fe2-aee4-426e-a197-142c90347b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hourlyprecipitation</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 01:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 02:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 03:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 04:51:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  hourlyprecipitation  hourlywindspeed\n",
       "0 2020-01-01 00:51:00                  0.0              8.0\n",
       "1 2020-01-01 01:51:00                  0.0              8.0\n",
       "2 2020-01-01 02:51:00                  0.0             14.0\n",
       "3 2020-01-01 03:51:00                  0.0             11.0\n",
       "4 2020-01-01 04:51:00                  0.0              6.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "935261b7-ae23-427c-97ff-ea31aa4e44c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 56098 entries, 0 to 11638\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   date                 56098 non-null  datetime64[ns]\n",
      " 1   hourlyprecipitation  56098 non-null  float64       \n",
      " 2   hourlywindspeed      56098 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(2)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "hourly_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a7dcb502-d1d1-447d-aa68-11bff0dc53b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>hourlyprecipitation</th>\n",
       "      <th>hourlywindspeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56098</td>\n",
       "      <td>56098.000000</td>\n",
       "      <td>56098.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-05-29 21:14:19.618881024</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>4.537238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 00:51:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-03-18 19:01:45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-05-28 01:21:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-08-15 05:39:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-22 18:51:00</td>\n",
       "      <td>3.470000</td>\n",
       "      <td>2237.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056735</td>\n",
       "      <td>13.883208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                date  hourlyprecipitation  hourlywindspeed\n",
       "count                          56098         56098.000000     56098.000000\n",
       "mean   2022-05-29 21:14:19.618881024             0.010841         4.537238\n",
       "min              2020-01-01 00:51:00             0.000000         0.000000\n",
       "25%              2021-03-18 19:01:45             0.000000         0.000000\n",
       "50%              2022-05-28 01:21:00             0.000000         5.000000\n",
       "75%              2023-08-15 05:39:00             0.000000         7.000000\n",
       "max              2024-10-22 18:51:00             3.470000      2237.000000\n",
       "std                              NaN             0.056735        13.883208"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>daily_average_wind_speed</th>\n",
       "      <th>daily_peak_wind_speed</th>\n",
       "      <th>daily_snowfall</th>\n",
       "      <th>daily_snow_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11335</th>\n",
       "      <td>2022-12-22 23:59:00</td>\n",
       "      <td>0.23</td>\n",
       "      <td>8.6</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11389</th>\n",
       "      <td>2022-12-23 23:59:00</td>\n",
       "      <td>1.83</td>\n",
       "      <td>10.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11414</th>\n",
       "      <td>2022-12-24 23:59:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11439</th>\n",
       "      <td>2022-12-25 23:59:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11464</th>\n",
       "      <td>2022-12-26 23:59:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11489</th>\n",
       "      <td>2022-12-27 23:59:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.5</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>2022-12-28 23:59:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11541</th>\n",
       "      <td>2022-12-29 23:59:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.1</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11566</th>\n",
       "      <td>2022-12-30 23:59:00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11637</th>\n",
       "      <td>2022-12-31 23:59:00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         observation_date  daily_precipitation  daily_average_wind_speed  \\\n",
       "11335 2022-12-22 23:59:00                 0.23                       8.6   \n",
       "11389 2022-12-23 23:59:00                 1.83                      10.0   \n",
       "11414 2022-12-24 23:59:00                 0.00                      11.3   \n",
       "11439 2022-12-25 23:59:00                 0.00                       8.5   \n",
       "11464 2022-12-26 23:59:00                 0.00                       7.1   \n",
       "11489 2022-12-27 23:59:00                 0.00                       5.5   \n",
       "11516 2022-12-28 23:59:00                 0.00                       5.1   \n",
       "11541 2022-12-29 23:59:00                 0.00                       6.1   \n",
       "11566 2022-12-30 23:59:00                 0.00                       2.9   \n",
       "11637 2022-12-31 23:59:00                 0.28                       1.8   \n",
       "\n",
       "      daily_peak_wind_speed  daily_snowfall  daily_snow_depth  \n",
       "11335                  36.0           0.000               0.0  \n",
       "11389                  45.0           0.005               0.0  \n",
       "11414                  33.0           0.000               0.0  \n",
       "11439                  31.0           0.000               0.0  \n",
       "11464                  20.0           0.000               0.0  \n",
       "11489                  17.0           0.000               0.0  \n",
       "11516                  26.0           0.000               0.0  \n",
       "11541                  21.0           0.000               0.0  \n",
       "11566                  16.0           0.000               0.0  \n",
       "11637                  16.0           0.000               0.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f090eb94-a5b0-4d93-bf82-a596d2521b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1685 entries, 24 to 11637\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   observation_date          1685 non-null   datetime64[ns]\n",
      " 1   daily_precipitation       1685 non-null   float64       \n",
      " 2   daily_average_wind_speed  1685 non-null   float64       \n",
      " 3   daily_peak_wind_speed     1685 non-null   object        \n",
      " 4   daily_snowfall            1685 non-null   float64       \n",
      " 5   daily_snow_depth          1685 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(4), object(1)\n",
      "memory usage: 92.1+ KB\n"
     ]
    }
   ],
   "source": [
    "daily_weather_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8c074aa3-a5f2-4586-8748-411e1e6c11da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>observation_date</th>\n",
       "      <th>daily_precipitation</th>\n",
       "      <th>daily_average_wind_speed</th>\n",
       "      <th>daily_snowfall</th>\n",
       "      <th>daily_snow_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1685</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>1685.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-06-13 09:20:28.308605184</td>\n",
       "      <td>0.145490</td>\n",
       "      <td>5.008131</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.160861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2020-01-01 23:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-04-08 23:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-06-21 23:59:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-08-17 23:59:00</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-10-21 23:59:00</td>\n",
       "      <td>7.130000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.421219</td>\n",
       "      <td>2.339557</td>\n",
       "      <td>0.503529</td>\n",
       "      <td>1.062031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    observation_date  daily_precipitation  \\\n",
       "count                           1685          1685.000000   \n",
       "mean   2022-06-13 09:20:28.308605184             0.145490   \n",
       "min              2020-01-01 23:59:00             0.000000   \n",
       "25%              2021-04-08 23:59:00             0.000000   \n",
       "50%              2022-06-21 23:59:00             0.000000   \n",
       "75%              2023-08-17 23:59:00             0.060000   \n",
       "max              2024-10-21 23:59:00             7.130000   \n",
       "std                              NaN             0.421219   \n",
       "\n",
       "       daily_average_wind_speed  daily_snowfall  daily_snow_depth  \n",
       "count               1685.000000     1685.000000       1685.000000  \n",
       "mean                   5.008131        0.040890          0.160861  \n",
       "min                    0.600000        0.000000          0.000000  \n",
       "25%                    3.200000        0.000000          0.000000  \n",
       "50%                    4.700000        0.000000          0.000000  \n",
       "75%                    6.400000        0.000000          0.000000  \n",
       "max                   14.200000       14.800000         14.000000  \n",
       "std                    2.339557        0.503529          1.062031  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    date DATETIME,\n",
    "    hourly_precipitation FLOAT,\n",
    "    hourly_wind_speed FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    date DATETIME,\n",
    "    daily_precipitation FLOAT,\n",
    "    daily_average_wind_speed FLOAT,\n",
    "    daily_peak_wind_speed FLOAT\n",
    "    daily_snowfall FLOAT,\n",
    "    daily_snow_depth FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips(\n",
    "     tpep_pickup_datetime DATETIME, \n",
    "     tpep_dropoff_datetime DATETIME,\n",
    "     trip_distance FLOAT, \n",
    "     latitude_pickup FLOAT, \n",
    "     longitude_pickup FLOAT, \n",
    "     latitude_dropoff FLOAT, \n",
    "     longitude_dropoff FLOAT, \n",
    "     fare_amount FLOAT, \n",
    "     extra FLOAT, \n",
    "     mta_tax FLOAT, \n",
    "     tip_amount FLOAT, \n",
    "     tolls_amount FLOAT, \n",
    "     improvement_surcharge FLOAT, \n",
    "     congestion_surcharge FLOAT, \n",
    "     airport_fee FLOAT, \n",
    "     total_amount FLOAT,\n",
    "     total_money FLOAT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips(\n",
    "    request_datetime DATETIME,\n",
    "    on_scene_datetime DATETIME,\n",
    "    pickup_datetime DATETIME,\n",
    "    dropoff_datetime DATETIME,\n",
    "    pickup_lat FLOAT,\n",
    "    pickup_lon FLOAT,\n",
    "    dropoff_lat FLOAT,\n",
    "    dropoff_lon FLOAT,\n",
    "    trip_miles FLOAT,\n",
    "    total_fare FLOAT,\n",
    "    tips FLOAT\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    with open(DATABASE_SCHEMA_FILE, \"r\") as f:\n",
    "        schema_sql = f.read()\n",
    "    schema_stmts = [stmt.strip() for stmt in schema_sql.split(\";\") if stmt.strip()]\n",
    "    for stmt in schema_stmts:\n",
    "        connection.execute(db.text(stmt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    with engine.connect() as connection:\n",
    "        for table_name, df in table_to_df_dict.items():\n",
    "            \n",
    "            df.to_sql(table_name, con=connection, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "45d6c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "74004f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    query_filepath = os.path.join(QUERY_DIRECTORY, outfile)\n",
    "    with open(query_filepath, 'w') as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"taxi_most_popular_hour.sql\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "SELECT \n",
    "    strftime('%H', tpep_pickup_datetime) AS hour,\n",
    "    COUNT(*) AS ride_count\n",
    "FROM \n",
    "    taxi_trips\n",
    "WHERE \n",
    "    tpep_pickup_datetime BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "GROUP BY \n",
    "    hour\n",
    "ORDER BY \n",
    "    ride_count DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_1)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "df_results1 = pd.read_sql(QUERY_1, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5327fccd-4856-417b-b1dc-8d894f293231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   hour  ride_count\n",
      "0    17        1501\n",
      "1    18        1455\n",
      "2    15        1450\n",
      "3    16        1352\n",
      "4    19        1316\n",
      "5    13        1271\n",
      "6    14        1269\n",
      "7    12        1229\n",
      "8    11        1150\n",
      "9    20        1079\n",
      "10   10        1074\n",
      "11   21         987\n",
      "12   09         908\n",
      "13   22         891\n",
      "14   08         785\n",
      "15   23         751\n",
      "16   07         606\n",
      "17   00         506\n",
      "18   06         350\n",
      "19   01         326\n",
      "20   02         212\n",
      "21   03         148\n",
      "22   05         128\n",
      "23   04         112\n"
     ]
    }
   ],
   "source": [
    "print(df_results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05591da3-068d-421f-b1e1-4bd53e493406",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "647cc27e-3626-4be8-b354-be7be0094bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2_FILENAME = \"uber_most_popular_day.sql\"\n",
    "\n",
    "QUERY_2 = \"\"\"\n",
    "SELECT \n",
    "    strftime('%w', pickup_datetime) AS day_of_week,  -- 0 = Sunday, 6 = Saturday\n",
    "    COUNT(*) AS ride_count\n",
    "FROM \n",
    "    uber_trips\n",
    "WHERE \n",
    "    pickup_datetime BETWEEN '2020-01-01' AND '2024-08-31'\n",
    "GROUP BY \n",
    "    day_of_week\n",
    "ORDER BY \n",
    "    ride_count DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c919940-cf72-4a31-b5f6-42a101a555b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_2)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "df_results2 = pd.read_sql(QUERY_2, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d61c78aa-be9b-4679-8695-887882fedc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, QUERY_2_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d4cce2a7-9629-475e-a603-dbf816a274c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  day_of_week  ride_count\n",
      "0           6        3372\n",
      "1           5        3287\n",
      "2           4        3009\n",
      "3           0        2926\n",
      "4           3        2915\n",
      "5           2        2697\n",
      "6           1        2425\n"
     ]
    }
   ],
   "source": [
    "print(df_results2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a26aa12-e761-48b8-9783-5815eb6b0989",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b6785837-9ff6-4cdc-b70d-8b65d8edf97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3_FILENAME = \"jan_per_distance.sql\"\n",
    "\n",
    "QUERY_3 = \"\"\"\n",
    "SELECT \n",
    "    trip_distance\n",
    "FROM (\n",
    "    SELECT \n",
    "        CAST(trip_distance AS FLOAT) AS trip_distance\n",
    "    FROM taxi_trips \n",
    "    WHERE tpep_pickup_datetime BETWEEN '2024-01-01' AND '2024-01-31'\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        CAST(trip_miles AS FLOAT) AS trip_distance\n",
    "    FROM uber_trips \n",
    "    WHERE pickup_datetime BETWEEN '2024-01-01' AND '2024-01-31'\n",
    ") AS combined_results\n",
    "WHERE trip_distance IS NOT NULL\n",
    "ORDER BY trip_distance\n",
    "LIMIT 1 OFFSET (\n",
    "    SELECT CAST(COUNT(*) * 0.95 AS INTEGER) \n",
    "    FROM (\n",
    "        SELECT \n",
    "            CAST(trip_distance AS FLOAT) AS trip_distance\n",
    "        FROM taxi_trips \n",
    "        WHERE tpep_pickup_datetime BETWEEN '2024-01-01' AND '2024-01-31'\n",
    "        \n",
    "        UNION ALL\n",
    "        \n",
    "        SELECT \n",
    "            CAST(trip_miles AS FLOAT) AS trip_distance\n",
    "        FROM uber_trips \n",
    "        WHERE pickup_datetime BETWEEN '2024-01-01' AND '2024-01-31'\n",
    "    )\n",
    ") - 1;\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b60b5c07-e5ab-45cc-9e0b-72b6ee00bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_3)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "df_results3 = pd.read_sql(QUERY_3, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bb16adca-d005-4ccb-a4c5-9701caa16962",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, QUERY_3_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "97200025-a70d-4505-a506-358ded444540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trip_distance\n",
      "0          13.45\n"
     ]
    }
   ],
   "source": [
    "print(df_results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a14a5e8-4bb3-4cb4-94c3-d48b5f62f7d3",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d2f2e906-2600-4219-9d72-dfce6b1ec006",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4_FILENAME = \"top10_busiest_day.sql\"\n",
    "\n",
    "QUERY_4 = \"\"\"\n",
    "WITH combined_rides AS (\n",
    "    SELECT \n",
    "        DATE(tpep_pickup_datetime) AS trip_date,\n",
    "        COUNT(*) AS total_rides,\n",
    "        AVG(trip_distance) AS avg_distance\n",
    "    FROM taxi_trips\n",
    "    WHERE tpep_pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "    GROUP BY trip_date\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    SELECT \n",
    "        DATE(pickup_datetime) AS trip_date,\n",
    "        COUNT(*) AS total_rides,\n",
    "        AVG(trip_miles) AS avg_distance\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n",
    "    GROUP BY trip_date\n",
    "),\n",
    "daily_stats AS (\n",
    "    SELECT\n",
    "        trip_date,\n",
    "        SUM(total_rides) AS total_rides,\n",
    "        AVG(avg_distance) AS avg_distance\n",
    "    FROM combined_rides\n",
    "    GROUP BY trip_date\n",
    ")\n",
    "SELECT \n",
    "    ds.trip_date,\n",
    "    ds.total_rides,\n",
    "    ds.avg_distance,\n",
    "    dw.daily_precipitation AS avg_precipitation,\n",
    "    dw.daily_average_wind_speed AS avg_wind_speed\n",
    "FROM daily_stats ds\n",
    "LEFT JOIN daily_weather dw ON ds.trip_date = DATE(dw.date)\n",
    "ORDER BY ds.total_rides DESC\n",
    "LIMIT 10;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "97ac77ab-594a-4e38-9329-0d212363112b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such column: dw.date\n[SQL: \nWITH combined_rides AS (\n    SELECT \n        DATE(tpep_pickup_datetime) AS trip_date,\n        COUNT(*) AS total_rides,\n        AVG(trip_distance) AS avg_distance\n    FROM taxi_trips\n    WHERE tpep_pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n    GROUP BY trip_date\n\n    UNION ALL\n\n    SELECT \n        DATE(pickup_datetime) AS trip_date,\n        COUNT(*) AS total_rides,\n        AVG(trip_miles) AS avg_distance\n    FROM uber_trips\n    WHERE pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n    GROUP BY trip_date\n),\ndaily_stats AS (\n    SELECT\n        trip_date,\n        SUM(total_rides) AS total_rides,\n        AVG(avg_distance) AS avg_distance\n    FROM combined_rides\n    GROUP BY trip_date\n)\nSELECT \n    ds.trip_date,\n    ds.total_rides,\n    ds.avg_distance,\n    dw.daily_precipitation AS avg_precipitation,\n    dw.daily_average_wind_speed AS avg_wind_speed\nFROM daily_stats ds\nLEFT JOIN daily_weather dw ON ds.trip_date = DATE(dw.date)\nORDER BY ds.total_rides DESC\nLIMIT 10;\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[1;32m   1968\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1969\u001b[0m         )\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 924\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: dw.date",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[131], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# execute query either via sqlalchemy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m engine\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m con:\n\u001b[0;32m----> 3\u001b[0m     results \u001b[38;5;241m=\u001b[39m con\u001b[38;5;241m.\u001b[39mexecute(db\u001b[38;5;241m.\u001b[39mtext(QUERY_4))\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m      4\u001b[0m results\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# or via pandas\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1420\u001b[0m         distilled_parameters,\n\u001b[1;32m   1421\u001b[0m         execution_options \u001b[38;5;129;01mor\u001b[39;00m NO_OPTIONS,\n\u001b[1;32m   1422\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39m_execute_clauseelement(\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;28mself\u001b[39m, distilled_params, execution_options\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[1;32m   1630\u001b[0m )\n\u001b[1;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1639\u001b[0m )\n\u001b[0;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[1;32m   1641\u001b[0m     dialect,\n\u001b[1;32m   1642\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[1;32m   1643\u001b[0m     compiled_sql,\n\u001b[1;32m   1644\u001b[0m     distilled_parameters,\n\u001b[1;32m   1645\u001b[0m     execution_options,\n\u001b[1;32m   1646\u001b[0m     compiled_sql,\n\u001b[1;32m   1647\u001b[0m     distilled_parameters,\n\u001b[1;32m   1648\u001b[0m     elem,\n\u001b[1;32m   1649\u001b[0m     extracted_params,\n\u001b[1;32m   1650\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[1;32m   1651\u001b[0m )\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[1;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1655\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m         ret,\n\u001b[1;32m   1660\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_single_context(\n\u001b[1;32m   1847\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1848\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1986\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[1;32m   1987\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1988\u001b[0m     )\n\u001b[1;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:2353\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2351\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2352\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2353\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   2354\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2355\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1967\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[1;32m   1968\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1969\u001b[0m         )\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1974\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[1;32m   1979\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sqlalchemy/engine/default.py:924\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 924\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such column: dw.date\n[SQL: \nWITH combined_rides AS (\n    SELECT \n        DATE(tpep_pickup_datetime) AS trip_date,\n        COUNT(*) AS total_rides,\n        AVG(trip_distance) AS avg_distance\n    FROM taxi_trips\n    WHERE tpep_pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n    GROUP BY trip_date\n\n    UNION ALL\n\n    SELECT \n        DATE(pickup_datetime) AS trip_date,\n        COUNT(*) AS total_rides,\n        AVG(trip_miles) AS avg_distance\n    FROM uber_trips\n    WHERE pickup_datetime BETWEEN '2023-01-01' AND '2023-12-31'\n    GROUP BY trip_date\n),\ndaily_stats AS (\n    SELECT\n        trip_date,\n        SUM(total_rides) AS total_rides,\n        AVG(avg_distance) AS avg_distance\n    FROM combined_rides\n    GROUP BY trip_date\n)\nSELECT \n    ds.trip_date,\n    ds.total_rides,\n    ds.avg_distance,\n    dw.daily_precipitation AS avg_precipitation,\n    dw.daily_average_wind_speed AS avg_wind_speed\nFROM daily_stats ds\nLEFT JOIN daily_weather dw ON ds.trip_date = DATE(dw.date)\nORDER BY ds.total_rides DESC\nLIMIT 10;\n]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_4)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "df_results4 = pd.read_sql(QUERY_4, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a91a70-c23f-4994-b630-5011c6e6e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, QUERY_4_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d968de-f484-4855-b7e4-8183e05440e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760be244-dee8-4ee8-8ef1-a0b19d603882",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59f1254-a234-421a-a4bf-b9b0e5dfccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5_FILENAME = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2734136-3e79-4153-b72f-cb8d0701d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_5)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "df_results5 = pd.read_sql(QUERY_5, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217a483-657d-400e-b88f-74d394646b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, QUERY_5_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f752b461-47e6-4c57-a7ff-b42c533a4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f9a7f6-2f0a-4112-b0a7-eaa376d13efe",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd93a4-fbe4-4d36-86cc-1b2efd8a3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6_FILENAME = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09957503-b834-4448-8f6d-c53f60a9e8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute query either via sqlalchemy\n",
    "with engine.connect() as con:\n",
    "    results = con.execute(db.text(QUERY_6)).fetchall()\n",
    "results\n",
    "\n",
    "# or via pandas\n",
    "df_results6 = pd.read_sql(QUERY_6, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8fced-fb4f-41ff-804b-6c2ab027d449",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, QUERY_6_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af1611-289c-4639-ae97-71692e0e9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def taxi_popular_hour(dataframe):\n",
    "    # Sort the data by the 'hour' column to ensure it's in order\n",
    "    df_sorted = df.sort_values(by=\"hour\")\n",
    "    \n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(df_sorted[\"hour\"], df_sorted[\"ride_count\"], color=\"skyblue\", edgecolor=\"black\")\n",
    "    \n",
    "    # Add labels and title\n",
    "    plt.xlabel(\"Hour\", fontsize=12)\n",
    "    plt.ylabel(\"Number of Rides\", fontsize=12)\n",
    "    plt.title(\"Number of Rides by Hour of the Day\", fontsize=14)\n",
    "    plt.xticks(df_sorted[\"hour\"], fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924acd44-0916-4cd7-8d37-830b1d6aea16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
